---
title: "R03_INLA"
author: "Toon Van Daele"
date: "26 augustus 2019"
output:
  html_document:
    code_folding: hide
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
library(knitr)
library(mgcv)
library(gratia)
library(tidyverse)
opts_chunk$set(echo = TRUE)
source(file = "../R/9_function.R")
source(file = "../R/9b_plot_function.R")
```

# INLA

We use the (confidence intervals) of the first & second derivative of the smoother s(year) as an indication wether the species is increasing or not.

INLA with random intercept.

We use the 'df_pp' data frame:

- obs = number of observations
- ncells = number of cells
- cobs = number of observations of species class
- ncobs = number of cells (cobs >= 1)

```{r load-preprocessed-data, include=FALSE}
df_pp <- readRDS(file = "../data/df_pp.RDS")
spec_names <- readRDS(file = "../data/spec_names.RDS")
```

```{r select-species}
spec_id <- "2206086" #"1718308" #"2715482"
df <- filter(df_pp, taxonKey == spec_id)
sp_n <- spec_names %>% filter(taxonKey == spec_id) %>% .$spn
fyear <- min(df$year) # First year
lyear <- max(df$year) # Last year
```

__species id: `r spec_id`  (name: `r sp_n`)___

```{r plot-time-series, echo=FALSE}
plot_ts(df)
```


## Model A: ncells ~ year

- The response is ncells (number of cells with observation).
- Negative binomial (with loglink) as overdispersion is exepected very often.
- The number of cells is actually a proportion of a total number of possible cells, but the number of cells is always much smaller than the total number of cells.




```{r gam-A}
# 2 modellen met verschillende aantal vrijheidsgraden.


gA <- gam(ncells ~ s(year, m = 3, bs = "tp"), family = nb(),
                data = df, method = "REML")
```

By default m = 2. This forces the 2nd derivative to 0 at the endpoints of the smoother. m = 3 allows values >< 0 at the endpoints

```{r summary-A}
summary(gA)
```

```{r plots-A}
appraise(gA)
```


```{r draw-smoothers-A, fig.height= 3}
draw(gA)
```

```{r prediction-A}
df_n <- data.frame(year = seq(from = fyear, to = lyear,
                                    length.out = (lyear - fyear) * 5))
temp <- predict(object = gA, newdata = df_n, type = "iterms",
                interval = "prediction", se.fit = TRUE)
intercept <- unname(gA$coefficients[1])
df_n$fit <- exp(temp$fit[,1] + intercept)
df_n$ucl <- exp(temp$fit[,1] + intercept + temp$se.fit[,1] * 1.96)
df_n$lcl <- exp(temp$fit[,1] + intercept - temp$se.fit[,1] * 1.96)
```


```{r derivatives-smoother-A, fig.height = 3}
# Calculate first and second derivative + conf. interval
gderiv <- syear_deriv(g = gA, dfrows = nrow(df_n))
draw(gderiv[["deriv1"]])
```

```{r second derivative-A, fig.height = 3}
draw(gderiv[["deriv2"]])
```



```{r em_level-A}
df_n <- bind_cols(df_n, gderiv[["em"]])

# Create plot with conf. interval + colour for emerging status
plot_ribbon_em(df_n = df_n, df = df, printplot = FALSE, saveplot = FALSE)
```


## Model B: obs ~ s(year) + s(cobs)

Include the number of cells with observations from the species class as a covariate to account for the search effort.

Assumption: Variation of class ~ search effort. The data of the individual species have no influence on the data of the class (species <<<< class).

This approach potentially allows to reduce the two year lag time (to be tested)!

```{r plot-B-ts}
df %>%
  dplyr::select(year, obs, cobs) %>%
  group_by(year) %>%
  gather(key = type, value = n, -year) %>%
  ggplot(aes(x = year, y = n)) + geom_point() + 
    facet_wrap(~type, scales = "free_y")
```


```{r}
#GGally::ggpairs(df[,c("ncells", "year", "ncobs")])
ggplot(df, aes(x = cobs, y = obs)) + geom_point()
```


```{r}

# aantal waarnemingen van de soortgroep als offset ipv smoother
# lineaire fit -> 

# Op hokniveau -> hok als random intercept +  aantal waarneminge nvan de groep per hok en jaar




gB <- gam(obs ~ s(year, m = 3, bs = "tp") +
            s(cobs, bs = "ts"), family = nb(),
                data = df, method = "REML")
```


```{r summary-B}
summary(gB)
```

```{r plots-B}
appraise(gB)
```

```{r draw-smoothers-B}
draw(gB)
```

```{r prediction-B}
df_n <- df
temp <- predict(object = gB, newdata = df_n, type = "iterms",
                interval = "prediction", se.fit = TRUE)
intercept <- unname(gB$coefficients[1])
df_n$fit <- exp(temp$fit[,1] + intercept)
df_n$ucl <- exp(temp$fit[,1] + intercept + temp$se.fit[,1] * 1.96)
df_n$lcl <- exp(temp$fit[,1] + intercept - temp$se.fit[,1] * 1.96)
```


```{r derivatives-smoother-B}
# Calculate first and second derivative + conf. interval
gderiv <- syear_deriv(g = gB, dfrows = nrow(df_n))

```

```{r first derivative-B}
draw(gderiv[["deriv1"]])
```

```{r second derivative-B}
draw(gderiv[["deriv2"]])
```


```{r em_level-B}
df_n <- bind_cols(df_n, gderiv[["em"]])

# Plot with conf. interval + colour for emerging status
plot_ribbon_em(df_n = df_n, df = df, printplot = FALSE, saveplot = FALSE)
```



## Model C: Adding temporal correlacton AR1

GAMM doesn't accept the negative binomial distribution. We try 
GAMM with quasipoisson.

```{r}
gC <- gamm(ncells ~ s(year, m = 3, bs = "ts"),
           correlation = corAR1(),
           family = quasipoisson,
           data = df, method = "REML")
```


- C. obs ~ year + cobs  (neg. binom - loglink)
- D. ncells ~ year + cobs  (neg. binom - loglink) ncells <<<< tot. number of cells
- E. ncells ~ year + ncobs  (neg. binom - loglink) ncells <<<< tot. number of cells

By year + cellID

## 

